{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kerasANN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praneethcruzon/Data-Analytics-Laboratory/blob/master/kerasANNsample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViEDqudGaRbN",
        "colab_type": "text"
      },
      "source": [
        "#Simple ANN using keras\n",
        "\n",
        "*   Sequential creates a sequence of layers\n",
        "*   Dense creates a fully connected network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18SppJESY164",
        "colab_type": "code",
        "outputId": "77dcb4c5-d6e2-496f-c880-e51417dc44a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htL0FMcibjl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder,MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3JVDDX8bsYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = load_iris()\n",
        "print(iris)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeTriLTObwgn",
        "colab_type": "code",
        "outputId": "27bc31ec-14aa-4c21-880e-8446493678f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(iris.feature_names)\n",
        "print(iris.target_names)\n",
        "#print(iris.DESCR)\n",
        "#print(iris.data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM0EDqI7dBy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data = iris.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA4eQ2z4cPW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ee15d905-a4f0-40a1-cd37-570079b8150a"
      },
      "source": [
        "target_class = iris.target\n",
        "#iris['target']\n",
        "target_class"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdMc0Va9ebEr",
        "colab_type": "text"
      },
      "source": [
        "###Use z-score normalization to convert data with mean 0 and variance 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x57GIpKJdSS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8ee52f0-a80b-424a-b912-a2f9a75779bc"
      },
      "source": [
        "scaler = MinMaxScaler([-1,1])\n",
        "input_scaled = scaler.fit_transform(input_data)\n",
        "print(input_scaled)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-5.55555556e-01  2.50000000e-01 -8.64406780e-01 -9.16666667e-01]\n",
            " [-6.66666667e-01 -1.66666667e-01 -8.64406780e-01 -9.16666667e-01]\n",
            " [-7.77777778e-01  0.00000000e+00 -8.98305085e-01 -9.16666667e-01]\n",
            " [-8.33333333e-01 -8.33333333e-02 -8.30508475e-01 -9.16666667e-01]\n",
            " [-6.11111111e-01  3.33333333e-01 -8.64406780e-01 -9.16666667e-01]\n",
            " [-3.88888889e-01  5.83333333e-01 -7.62711864e-01 -7.50000000e-01]\n",
            " [-8.33333333e-01  1.66666667e-01 -8.64406780e-01 -8.33333333e-01]\n",
            " [-6.11111111e-01  1.66666667e-01 -8.30508475e-01 -9.16666667e-01]\n",
            " [-9.44444444e-01 -2.50000000e-01 -8.64406780e-01 -9.16666667e-01]\n",
            " [-6.66666667e-01 -8.33333333e-02 -8.30508475e-01 -1.00000000e+00]\n",
            " [-3.88888889e-01  4.16666667e-01 -8.30508475e-01 -9.16666667e-01]\n",
            " [-7.22222222e-01  1.66666667e-01 -7.96610169e-01 -9.16666667e-01]\n",
            " [-7.22222222e-01 -1.66666667e-01 -8.64406780e-01 -1.00000000e+00]\n",
            " [-1.00000000e+00 -1.66666667e-01 -9.66101695e-01 -1.00000000e+00]\n",
            " [-1.66666667e-01  6.66666667e-01 -9.32203390e-01 -9.16666667e-01]\n",
            " [-2.22222222e-01  1.00000000e+00 -8.30508475e-01 -7.50000000e-01]\n",
            " [-3.88888889e-01  5.83333333e-01 -8.98305085e-01 -7.50000000e-01]\n",
            " [-5.55555556e-01  2.50000000e-01 -8.64406780e-01 -8.33333333e-01]\n",
            " [-2.22222222e-01  5.00000000e-01 -7.62711864e-01 -8.33333333e-01]\n",
            " [-5.55555556e-01  5.00000000e-01 -8.30508475e-01 -8.33333333e-01]\n",
            " [-3.88888889e-01  1.66666667e-01 -7.62711864e-01 -9.16666667e-01]\n",
            " [-5.55555556e-01  4.16666667e-01 -8.30508475e-01 -7.50000000e-01]\n",
            " [-8.33333333e-01  3.33333333e-01 -1.00000000e+00 -9.16666667e-01]\n",
            " [-5.55555556e-01  8.33333333e-02 -7.62711864e-01 -6.66666667e-01]\n",
            " [-7.22222222e-01  1.66666667e-01 -6.94915254e-01 -9.16666667e-01]\n",
            " [-6.11111111e-01 -1.66666667e-01 -7.96610169e-01 -9.16666667e-01]\n",
            " [-6.11111111e-01  1.66666667e-01 -7.96610169e-01 -7.50000000e-01]\n",
            " [-5.00000000e-01  2.50000000e-01 -8.30508475e-01 -9.16666667e-01]\n",
            " [-5.00000000e-01  1.66666667e-01 -8.64406780e-01 -9.16666667e-01]\n",
            " [-7.77777778e-01  0.00000000e+00 -7.96610169e-01 -9.16666667e-01]\n",
            " [-7.22222222e-01 -8.33333333e-02 -7.96610169e-01 -9.16666667e-01]\n",
            " [-3.88888889e-01  1.66666667e-01 -8.30508475e-01 -7.50000000e-01]\n",
            " [-5.00000000e-01  7.50000000e-01 -8.30508475e-01 -1.00000000e+00]\n",
            " [-3.33333333e-01  8.33333333e-01 -8.64406780e-01 -9.16666667e-01]\n",
            " [-6.66666667e-01 -8.33333333e-02 -8.30508475e-01 -9.16666667e-01]\n",
            " [-6.11111111e-01  0.00000000e+00 -9.32203390e-01 -9.16666667e-01]\n",
            " [-3.33333333e-01  2.50000000e-01 -8.98305085e-01 -9.16666667e-01]\n",
            " [-6.66666667e-01  3.33333333e-01 -8.64406780e-01 -1.00000000e+00]\n",
            " [-9.44444444e-01 -1.66666667e-01 -8.98305085e-01 -9.16666667e-01]\n",
            " [-5.55555556e-01  1.66666667e-01 -8.30508475e-01 -9.16666667e-01]\n",
            " [-6.11111111e-01  2.50000000e-01 -8.98305085e-01 -8.33333333e-01]\n",
            " [-8.88888889e-01 -7.50000000e-01 -8.98305085e-01 -8.33333333e-01]\n",
            " [-9.44444444e-01  0.00000000e+00 -8.98305085e-01 -9.16666667e-01]\n",
            " [-6.11111111e-01  2.50000000e-01 -7.96610169e-01 -5.83333333e-01]\n",
            " [-5.55555556e-01  5.00000000e-01 -6.94915254e-01 -7.50000000e-01]\n",
            " [-7.22222222e-01 -1.66666667e-01 -8.64406780e-01 -8.33333333e-01]\n",
            " [-5.55555556e-01  5.00000000e-01 -7.96610169e-01 -9.16666667e-01]\n",
            " [-8.33333333e-01  0.00000000e+00 -8.64406780e-01 -9.16666667e-01]\n",
            " [-4.44444444e-01  4.16666667e-01 -8.30508475e-01 -9.16666667e-01]\n",
            " [-6.11111111e-01  8.33333333e-02 -8.64406780e-01 -9.16666667e-01]\n",
            " [ 5.00000000e-01  0.00000000e+00  2.54237288e-01  8.33333333e-02]\n",
            " [ 1.66666667e-01  0.00000000e+00  1.86440678e-01  1.66666667e-01]\n",
            " [ 4.44444444e-01 -8.33333333e-02  3.22033898e-01  1.66666667e-01]\n",
            " [-3.33333333e-01 -7.50000000e-01  1.69491525e-02  2.22044605e-16]\n",
            " [ 2.22222222e-01 -3.33333333e-01  2.20338983e-01  1.66666667e-01]\n",
            " [-2.22222222e-01 -3.33333333e-01  1.86440678e-01  2.22044605e-16]\n",
            " [ 1.11111111e-01  8.33333333e-02  2.54237288e-01  2.50000000e-01]\n",
            " [-6.66666667e-01 -6.66666667e-01 -2.20338983e-01 -2.50000000e-01]\n",
            " [ 2.77777778e-01 -2.50000000e-01  2.20338983e-01  2.22044605e-16]\n",
            " [-5.00000000e-01 -4.16666667e-01 -1.69491525e-02  8.33333333e-02]\n",
            " [-6.11111111e-01 -1.00000000e+00 -1.52542373e-01 -2.50000000e-01]\n",
            " [-1.11111111e-01 -1.66666667e-01  8.47457627e-02  1.66666667e-01]\n",
            " [-5.55555556e-02 -8.33333333e-01  1.69491525e-02 -2.50000000e-01]\n",
            " [-4.44089210e-16 -2.50000000e-01  2.54237288e-01  8.33333333e-02]\n",
            " [-2.77777778e-01 -2.50000000e-01 -1.18644068e-01  2.22044605e-16]\n",
            " [ 3.33333333e-01 -8.33333333e-02  1.52542373e-01  8.33333333e-02]\n",
            " [-2.77777778e-01 -1.66666667e-01  1.86440678e-01  1.66666667e-01]\n",
            " [-1.66666667e-01 -4.16666667e-01  5.08474576e-02 -2.50000000e-01]\n",
            " [ 5.55555556e-02 -8.33333333e-01  1.86440678e-01  1.66666667e-01]\n",
            " [-2.77777778e-01 -5.83333333e-01 -1.69491525e-02 -1.66666667e-01]\n",
            " [-1.11111111e-01  0.00000000e+00  2.88135593e-01  4.16666667e-01]\n",
            " [-4.44089210e-16 -3.33333333e-01  1.69491525e-02  2.22044605e-16]\n",
            " [ 1.11111111e-01 -5.83333333e-01  3.22033898e-01  1.66666667e-01]\n",
            " [-4.44089210e-16 -3.33333333e-01  2.54237288e-01 -8.33333333e-02]\n",
            " [ 1.66666667e-01 -2.50000000e-01  1.18644068e-01  2.22044605e-16]\n",
            " [ 2.77777778e-01 -1.66666667e-01  1.52542373e-01  8.33333333e-02]\n",
            " [ 3.88888889e-01 -3.33333333e-01  2.88135593e-01  8.33333333e-02]\n",
            " [ 3.33333333e-01 -1.66666667e-01  3.55932203e-01  3.33333333e-01]\n",
            " [-5.55555556e-02 -2.50000000e-01  1.86440678e-01  1.66666667e-01]\n",
            " [-2.22222222e-01 -5.00000000e-01 -1.52542373e-01 -2.50000000e-01]\n",
            " [-3.33333333e-01 -6.66666667e-01 -5.08474576e-02 -1.66666667e-01]\n",
            " [-3.33333333e-01 -6.66666667e-01 -8.47457627e-02 -2.50000000e-01]\n",
            " [-1.66666667e-01 -4.16666667e-01 -1.69491525e-02 -8.33333333e-02]\n",
            " [-5.55555556e-02 -4.16666667e-01  3.89830508e-01  2.50000000e-01]\n",
            " [-3.88888889e-01 -1.66666667e-01  1.86440678e-01  1.66666667e-01]\n",
            " [-5.55555556e-02  1.66666667e-01  1.86440678e-01  2.50000000e-01]\n",
            " [ 3.33333333e-01 -8.33333333e-02  2.54237288e-01  1.66666667e-01]\n",
            " [ 1.11111111e-01 -7.50000000e-01  1.52542373e-01  2.22044605e-16]\n",
            " [-2.77777778e-01 -1.66666667e-01  5.08474576e-02  2.22044605e-16]\n",
            " [-3.33333333e-01 -5.83333333e-01  1.69491525e-02  2.22044605e-16]\n",
            " [-3.33333333e-01 -5.00000000e-01  1.52542373e-01 -8.33333333e-02]\n",
            " [-4.44089210e-16 -1.66666667e-01  2.20338983e-01  8.33333333e-02]\n",
            " [-1.66666667e-01 -5.00000000e-01  1.69491525e-02 -8.33333333e-02]\n",
            " [-6.11111111e-01 -7.50000000e-01 -2.20338983e-01 -2.50000000e-01]\n",
            " [-2.77777778e-01 -4.16666667e-01  8.47457627e-02  2.22044605e-16]\n",
            " [-2.22222222e-01 -1.66666667e-01  8.47457627e-02 -8.33333333e-02]\n",
            " [-2.22222222e-01 -2.50000000e-01  8.47457627e-02  2.22044605e-16]\n",
            " [ 5.55555556e-02 -2.50000000e-01  1.18644068e-01  2.22044605e-16]\n",
            " [-5.55555556e-01 -5.83333333e-01 -3.22033898e-01 -1.66666667e-01]\n",
            " [-2.22222222e-01 -3.33333333e-01  5.08474576e-02  2.22044605e-16]\n",
            " [ 1.11111111e-01  8.33333333e-02  6.94915254e-01  1.00000000e+00]\n",
            " [-1.66666667e-01 -4.16666667e-01  3.89830508e-01  5.00000000e-01]\n",
            " [ 5.55555556e-01 -1.66666667e-01  6.61016949e-01  6.66666667e-01]\n",
            " [ 1.11111111e-01 -2.50000000e-01  5.59322034e-01  4.16666667e-01]\n",
            " [ 2.22222222e-01 -1.66666667e-01  6.27118644e-01  7.50000000e-01]\n",
            " [ 8.33333333e-01 -1.66666667e-01  8.98305085e-01  6.66666667e-01]\n",
            " [-6.66666667e-01 -5.83333333e-01  1.86440678e-01  3.33333333e-01]\n",
            " [ 6.66666667e-01 -2.50000000e-01  7.96610169e-01  4.16666667e-01]\n",
            " [ 3.33333333e-01 -5.83333333e-01  6.27118644e-01  4.16666667e-01]\n",
            " [ 6.11111111e-01  3.33333333e-01  7.28813559e-01  1.00000000e+00]\n",
            " [ 2.22222222e-01  0.00000000e+00  3.89830508e-01  5.83333333e-01]\n",
            " [ 1.66666667e-01 -4.16666667e-01  4.57627119e-01  5.00000000e-01]\n",
            " [ 3.88888889e-01 -1.66666667e-01  5.25423729e-01  6.66666667e-01]\n",
            " [-2.22222222e-01 -5.83333333e-01  3.55932203e-01  5.83333333e-01]\n",
            " [-1.66666667e-01 -3.33333333e-01  3.89830508e-01  9.16666667e-01]\n",
            " [ 1.66666667e-01  0.00000000e+00  4.57627119e-01  8.33333333e-01]\n",
            " [ 2.22222222e-01 -1.66666667e-01  5.25423729e-01  4.16666667e-01]\n",
            " [ 8.88888889e-01  5.00000000e-01  9.32203390e-01  7.50000000e-01]\n",
            " [ 8.88888889e-01 -5.00000000e-01  1.00000000e+00  8.33333333e-01]\n",
            " [-5.55555556e-02 -8.33333333e-01  3.55932203e-01  1.66666667e-01]\n",
            " [ 4.44444444e-01  0.00000000e+00  5.93220339e-01  8.33333333e-01]\n",
            " [-2.77777778e-01 -3.33333333e-01  3.22033898e-01  5.83333333e-01]\n",
            " [ 8.88888889e-01 -3.33333333e-01  9.32203390e-01  5.83333333e-01]\n",
            " [ 1.11111111e-01 -4.16666667e-01  3.22033898e-01  4.16666667e-01]\n",
            " [ 3.33333333e-01  8.33333333e-02  5.93220339e-01  6.66666667e-01]\n",
            " [ 6.11111111e-01  0.00000000e+00  6.94915254e-01  4.16666667e-01]\n",
            " [ 5.55555556e-02 -3.33333333e-01  2.88135593e-01  4.16666667e-01]\n",
            " [-4.44089210e-16 -1.66666667e-01  3.22033898e-01  4.16666667e-01]\n",
            " [ 1.66666667e-01 -3.33333333e-01  5.59322034e-01  6.66666667e-01]\n",
            " [ 6.11111111e-01 -1.66666667e-01  6.27118644e-01  2.50000000e-01]\n",
            " [ 7.22222222e-01 -3.33333333e-01  7.28813559e-01  5.00000000e-01]\n",
            " [ 1.00000000e+00  5.00000000e-01  8.30508475e-01  5.83333333e-01]\n",
            " [ 1.66666667e-01 -3.33333333e-01  5.59322034e-01  7.50000000e-01]\n",
            " [ 1.11111111e-01 -3.33333333e-01  3.89830508e-01  1.66666667e-01]\n",
            " [-4.44089210e-16 -5.00000000e-01  5.59322034e-01  8.33333333e-02]\n",
            " [ 8.88888889e-01 -1.66666667e-01  7.28813559e-01  8.33333333e-01]\n",
            " [ 1.11111111e-01  1.66666667e-01  5.59322034e-01  9.16666667e-01]\n",
            " [ 1.66666667e-01 -8.33333333e-02  5.25423729e-01  4.16666667e-01]\n",
            " [-5.55555556e-02 -1.66666667e-01  2.88135593e-01  4.16666667e-01]\n",
            " [ 4.44444444e-01 -8.33333333e-02  4.91525424e-01  6.66666667e-01]\n",
            " [ 3.33333333e-01 -8.33333333e-02  5.59322034e-01  9.16666667e-01]\n",
            " [ 4.44444444e-01 -8.33333333e-02  3.89830508e-01  8.33333333e-01]\n",
            " [-1.66666667e-01 -4.16666667e-01  3.89830508e-01  5.00000000e-01]\n",
            " [ 3.88888889e-01  0.00000000e+00  6.61016949e-01  8.33333333e-01]\n",
            " [ 3.33333333e-01  8.33333333e-02  5.93220339e-01  1.00000000e+00]\n",
            " [ 3.33333333e-01 -1.66666667e-01  4.23728814e-01  8.33333333e-01]\n",
            " [ 1.11111111e-01 -5.83333333e-01  3.55932203e-01  5.00000000e-01]\n",
            " [ 2.22222222e-01 -1.66666667e-01  4.23728814e-01  5.83333333e-01]\n",
            " [ 5.55555556e-02  1.66666667e-01  4.91525424e-01  8.33333333e-01]\n",
            " [-1.11111111e-01 -1.66666667e-01  3.89830508e-01  4.16666667e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpKTaV2lmJ61",
        "colab_type": "code",
        "outputId": "e4ef6afe-d1f3-44d4-897e-83bfdb10ad5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# One hot encoding\n",
        "enc = OneHotEncoder()\n",
        "hot_target_class = enc.fit_transform(target_class[:, np.newaxis]).toarray()\n",
        "hot_target_class"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq7XYLCaeUHl",
        "colab_type": "text"
      },
      "source": [
        "###Split into training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLRqJfAdeg4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(input_scaled,hot_target_class,test_size=0.3)\n",
        "#x_train\n",
        "#x_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVY3C-jEgwYC",
        "colab_type": "text"
      },
      "source": [
        "###Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csEvoq30ZZbB",
        "colab_type": "code",
        "outputId": "6faccc4a-03d1-4a04-9fbb-002ae107b71e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0820 05:52:17.604170 140324248418176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGe3Spzzaq7j",
        "colab_type": "text"
      },
      "source": [
        "###Can add any number of layers using model.add\n",
        "\n",
        "\n",
        "*   Compulsorily the first add function must have the parameter input_dim\n",
        "*   Default activation is linear function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHWkWPaPZfGP",
        "colab_type": "code",
        "outputId": "00ff9032-c886-4e8b-a0ff-a08a70e1161c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "h1 = model.add(Dense(6,activation=\"relu\",input_dim=4))\n",
        "h2=model.add(Dense(5,activation=\"relu\"))\n",
        "h3=model.add(Dense(7,activation=\"relu\"))\n",
        "o = model.add(Dense(3,activation=\"softmax\"))\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0820 05:52:20.008306 140324248418176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0820 05:52:20.028331 140324248418176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wopEmikabAz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Compile model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EznBdyTqg4dj",
        "colab_type": "code",
        "outputId": "e81e924d-2061-44c6-c344-990140edd8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"Adam\",metrics=['accuracy'])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0820 05:52:39.027478 140324248418176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0820 05:52:39.069175 140324248418176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_fOn5emhQnS",
        "colab_type": "code",
        "outputId": "4990e47f-9c7f-4d38-d354-71eaaae32005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 6)                 30        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 35        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 7)                 42        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 24        \n",
            "=================================================================\n",
            "Total params: 131\n",
            "Trainable params: 131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjOAs9liiLLt",
        "colab_type": "text"
      },
      "source": [
        "###Fit model\n",
        "\n",
        "*   Epoch - how many passes through the training dataset\n",
        "*   Batch - how many samples to consider before updating the weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgx38Bluifd2",
        "colab_type": "code",
        "outputId": "3d351d99-c0cc-4ab3-feb9-ee547d86f674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train,y_train,batch_size=10,epochs=50)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0820 05:52:45.917338 140324248418176 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0820 05:52:45.982973 140324248418176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.9995 - acc: 0.4000\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 209us/step - loss: 0.9728 - acc: 0.4190\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 201us/step - loss: 0.9488 - acc: 0.4381\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 208us/step - loss: 0.9228 - acc: 0.4571\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 192us/step - loss: 0.8974 - acc: 0.4667\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 214us/step - loss: 0.8709 - acc: 0.5048\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 185us/step - loss: 0.8462 - acc: 0.5143\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 177us/step - loss: 0.8183 - acc: 0.5619\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 206us/step - loss: 0.7906 - acc: 0.6571\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 186us/step - loss: 0.7619 - acc: 0.7143\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 239us/step - loss: 0.7326 - acc: 0.7333\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 181us/step - loss: 0.7052 - acc: 0.7333\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 179us/step - loss: 0.6784 - acc: 0.7238\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 222us/step - loss: 0.6532 - acc: 0.7333\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 179us/step - loss: 0.6279 - acc: 0.7238\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 225us/step - loss: 0.6036 - acc: 0.7238\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 216us/step - loss: 0.5800 - acc: 0.7238\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 210us/step - loss: 0.5567 - acc: 0.7429\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 214us/step - loss: 0.5342 - acc: 0.7524\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 217us/step - loss: 0.5155 - acc: 0.7524\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 243us/step - loss: 0.4958 - acc: 0.7619\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 214us/step - loss: 0.4792 - acc: 0.7714\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 235us/step - loss: 0.4638 - acc: 0.7810\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 210us/step - loss: 0.4501 - acc: 0.8000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 206us/step - loss: 0.4390 - acc: 0.8000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 191us/step - loss: 0.4270 - acc: 0.8095\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 200us/step - loss: 0.4175 - acc: 0.8190\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 186us/step - loss: 0.4073 - acc: 0.8286\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 237us/step - loss: 0.3994 - acc: 0.8381\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 213us/step - loss: 0.3908 - acc: 0.8381\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 179us/step - loss: 0.3826 - acc: 0.8476\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 195us/step - loss: 0.3751 - acc: 0.8571\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 168us/step - loss: 0.3683 - acc: 0.8571\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 187us/step - loss: 0.3609 - acc: 0.8571\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 173us/step - loss: 0.3539 - acc: 0.8571\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 216us/step - loss: 0.3472 - acc: 0.8571\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 200us/step - loss: 0.3407 - acc: 0.8571\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 165us/step - loss: 0.3340 - acc: 0.8571\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 242us/step - loss: 0.3279 - acc: 0.8667\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 189us/step - loss: 0.3216 - acc: 0.8667\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 176us/step - loss: 0.3151 - acc: 0.8857\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 230us/step - loss: 0.3083 - acc: 0.8857\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 192us/step - loss: 0.3003 - acc: 0.9048\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 191us/step - loss: 0.2922 - acc: 0.9333\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 206us/step - loss: 0.2833 - acc: 0.9333\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 226us/step - loss: 0.2739 - acc: 0.9333\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 243us/step - loss: 0.2655 - acc: 0.9333\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 195us/step - loss: 0.2567 - acc: 0.9429\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 190us/step - loss: 0.2476 - acc: 0.9429\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 171us/step - loss: 0.2393 - acc: 0.9429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9f86c947f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5LjdqvPjThF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "182130df-bf78-4496-a15b-176a3f324e88"
      },
      "source": [
        " score = model.evaluate(x_test,y_test, verbose=0)\n",
        " print('Test loss:', score[0])\n",
        " print('Test accuracy:', score[1])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.34025471674071417\n",
            "Test accuracy: 0.933333334657881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_pAG7IFnnqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}